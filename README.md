| ![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg) ![FastAPI](https://img.shields.io/badge/framework-FastAPI-009688?logo=fastapi) ![SQLite](https://img.shields.io/badge/Database-SQLite-003B57?logo=sqlite&logoColor=white) ![Test Coverage](https://img.shields.io/badge/test%20coverage-70%25-green.svg) ![MIT License](https://img.shields.io/badge/license-MIT-yellow.svg) |
|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|

# ğŸ“š API PÃºblica para Consulta de Livros â€“ Projeto de RecomendaÃ§Ã£o

## ğŸ“Œ DescriÃ§Ã£o
Este projeto faz parte do Tech Challenge, cujo objetivo Ã© aplicar de forma integrada os conhecimentos adquiridos na fase 1, desenvolvendo uma soluÃ§Ã£o completa de dados (**web scraping** do site [Books to Scrape](https://books.toscrape.com/)), desde a coleta atÃ© a disponibilizaÃ§Ã£o via API pÃºblica com endpoint para integraÃ§Ã£o com modelos de machine learning.(FastAPI + SQLite)

O desafio consiste em criar uma API pÃºblica para consulta de livros, alimentada por dados extraÃ­dos atravÃ©s de um sistema automatizado de web scraping do site Books to Scrape.

## Scraping
O script do web scraping localizado em `app/services/scraping.py` Ã© responsÃ¡vel por:
- **Extrair os dados brutos do site**:
A funÃ§Ã£o principal `scrape_books` tem o parÃ¢metro opcional `pages`, se ele for passado na chamada da funÃ§Ã£o, o scraping Ã© realizado sÃ³ naquele nÃºmero de pÃ¡ginas, se nÃ£o, a funÃ§Ã£o realiza o web scraping em todo o site, passando pÃ¡gina a pÃ¡gina, obtendo o link de cada livro e, entÃ£o, obtendo as informaÃ§Ãµes dele na sua respectiva pÃ¡gina.

- **Transformar e padronizar as informaÃ§Ãµes coletadas**:
Algumas infomaÃ§Ãµes, principalmente referentes a dinheiro foram formatadas para tirar o "Ã‚Â£" e serem assumidas como numÃ©ricas. 

### Bibliotecas usadas
Para realizar o web scraping utilizamos a biblioteca BeautifulSoup com o parser lxml (por ser mais rÃ¡pido e robusto).

### ExecuÃ§Ã£o do script
HÃ¡ duas formas de executar o script:
- A primeira delas Ã© via terminal com o comando python scraping.py (Dessa forma retornarÃ¡ as 2 primeiras pÃ¡ginas), dentro do diretÃ³rio `services`, porÃ©m essa forma vai apenas printar as informaÃ§Ãµes. 

- JÃ¡ a segunda Ã© integrada com a api, no endpoint `/api/v1/scraping/`. Essa forma irÃ¡ popular o banco de dados com os livros e com as categorias, chamando os serviÃ§os de book e category, validando unicidade do registro para evitar quebras por duplicidade.

## Banco de Dados
Esse projeto armazena os registros de books, categories e api_logs em um SQLite. Toda a manipulaÃ§Ã£o do banco de dados Ã© feita usando a biblioteca `sqlalchemy`. Sua criaÃ§Ã£o consiste na criaÃ§Ã£o dos modelos das tabelas (presentes na pasta `app/models`) e execuÃ§Ã£o do script `create_db.py` via terminal.

## API
A API foi projetada pensando em flexibilidade, escalabilidade, reutilizaÃ§Ã£o, boa organizaÃ§Ã£o arquitetural e facilidade de consumo por cientistas de dados, sistemas externos e serviÃ§os de recomendaÃ§Ã£o. Para isso escolhemos criÃ¡-la usando FastAPI. 

A organizaÃ§Ã£o dos cÃ³digos da API se dÃ¡ da seguinte forma:
- O `app/app.py` Ã© responsÃ¡vel por orquestrar a criaÃ§Ã£o da api, inclusÃ£o dos middleWares e das rotas.
- O diretÃ³rio `api/routers` contÃªm os arquivos de cada domÃ­nio de rotas existente na api, ou seja, o arquivo `book.py`, por exemplo, contÃªm os cÃ³digos responsÃ¡veis por criar cada uma das rotas de book.
- As funÃ§Ãµes que integram com o banco de dados ficam no diretÃ³rio `app/services` e sÃ£o chamadas nas respectivas funÃ§Ãµes de criaÃ§Ã£o do endpoint em `app/routers`.

### ğŸ“¡ Endpoints da API
#### Core

GET /api/v1/scraping â†’ Realiza o scraping e resgistro no banco de dados.

GET /api/v1/books â†’ Lista todos os livros.

GET /api/v1/books/{id} â†’ Detalhes de um livro especÃ­fico.

GET /api/v1/books/search?title={title}&category={category} â†’ Busca por tÃ­tulo/categoria.

GET /api/v1/categories â†’ Lista categorias disponÃ­veis.

GET /api/v1/health â†’ Status da API.

GET /callback â†’ Rota para receber a autenticaÃ§Ã£o

GET / â†’ Rota nÃ£o logada

GET /api/v1/home â†’ Rota para home

GET /login â†’ Rota para logar

GET /api/v1/logout â†’ Rota para sair da api

#### Insights (opcionais)

GET /api/v1/stats/overview â†’ EstatÃ­sticas gerais.

GET /api/v1/stats/categories â†’ EstatÃ­sticas por categoria.

GET /api/v1/books/top-rated â†’ Livros com melhor avaliaÃ§Ã£o.

GET /api/v1/books/price-range?min={min}&max={max} â†’ Livros por faixa de preÃ§o.

#### ML-ready (bÃ´nus)

*ObservaÃ§Ã£o: esses endpoints sÃ£o planejados e **nÃ£o** estÃ£o implementados atualmente.*

GET /api/v1/ml/features â†’ Dados formatados para features. (planejado)

GET /api/v1/ml/training-data â†’ Dataset para treinamento. (planejado)

POST /api/v1/ml/predictions â†’ Endpoint para prediÃ§Ãµes. (planejado)

#### Monitoramento & Analytics (bÃ´nus)

GET /api_logs â†’ InformaÃ§Ãµes de performance e logs das chamadas de api.


### ğŸ“Š Endpoints Detalhados (Diagramas de SequÃªncia)

Todos os endpoints possuem diagramas de sequÃªncia em `docs/uml/` descrevendo o fluxo de execuÃ§Ã£o:

#### Core
- [`sequence_scrape_populate.md`] (docs/uml/sequence_scrape_populate.md) â€” GET /scraping (scrape as informaÃ§Ãµes do site)
- [`sequence_list_books.md`](docs/uml/sequence_list_books.md) â€” GET /books (lista todos os livros)
- [`sequence_get_book.md`](docs/uml/sequence_get_book.md) â€” GET /books/{id} (livro especÃ­fico)
- [`sequence_search_books.md`](docs/uml/sequence_search_books.md) â€” GET /books/search (busca por tÃ­tulo/categoria)
- [`sequence_list_categories.md`](docs/uml/sequence_list_categories.md) â€” GET /categories (lista categorias)
- [`sequence_health.md`](docs/uml/sequence_health.md) â€” GET /health (status da API)

#### Insights
- [`sequence_stats_overview.md`](docs/uml/sequence_stats_overview.md) â€” GET /stats/overview (estatÃ­sticas gerais)
- [`sequence_stats_categories.md`](docs/uml/sequence_stats_categories.md) â€” GET /stats/categories (estatÃ­sticas por categoria)
- [`sequence_top_rated.md`](docs/uml/sequence_top_rated.md) â€” GET /books/top-rated (livros melhor avaliados)
- [`sequence_price_range.md`](docs/uml/sequence_price_range.md) â€” GET /books/price-range (livros por faixa de preÃ§o)

### DocumentaÃ§Ã£o da API (Swagger) 
O prÃ³prio FastAPI monta a documentaÃ§Ã£o no [link](https://mle-tech-chalenge-1.onrender.com/docs) usando as docstrings das funÃ§Ãµes de cada rota.

### ğŸ”„ Versionamento da API

Esta API utiliza versionamento por URL, identificado pelo prefixo /api/v1.

O versionamento explÃ­cito permite:

- Evoluir a API sem quebrar integraÃ§Ãµes existentes
- Garantir compatibilidade para consumidores antigos
- Facilitar a manutenÃ§Ã£o e a introduÃ§Ã£o de novas funcionalidades

#### EstratÃ©gia adotada

- /api/v1

  Primeira versÃ£o estÃ¡vel da API, contendo os endpoints core de consulta de livros, categorias, scraping, estatÃ­sticas e monitoramento.

- Novas versÃµes (v2, v3, â€¦)
SerÃ£o criadas quando houver:

 - MudanÃ§as incompatÃ­veis no formato de resposta (breaking changes)
  - AlteraÃ§Ãµes significativas na lÃ³gica dos endpoints
  - IntroduÃ§Ã£o de novos fluxos, como autenticaÃ§Ã£o diferente ou endpoints de ML em produÃ§Ã£o

#### Compatibilidade

- VersÃµes antigas da API continuarÃ£o disponÃ­veis por um perÃ­odo determinado, evitando impacto imediato nos consumidores.
- CorreÃ§Ãµes de bugs e melhorias que nÃ£o quebram compatibilidade poderÃ£o ser aplicadas dentro da mesma versÃ£o (v1).

#### BenefÃ­cios para Machine Learning

O versionamento Ã© especialmente importante para cenÃ¡rios de Machine Learning, pois garante:

  - Reprodutibilidade de experimentos
  - Estabilidade nos dados consumidos por pipelines de treino
  - SeguranÃ§a na evoluÃ§Ã£o de features e datasets ao longo do tempo

## AutenticaÃ§Ã£o
A autenticaÃ§Ã£o da API aproveita o gerenciador de acesso do GitHub por meio da biblioteca `githubkit`, como pode ser visto em `app/services/auth_middleware.py`. Isso Ã© interessante visto que nÃ£o precisamos gerenciar os usuÃ¡rios.
Algumas rotas, como docs, api_logs sÃ£o mantidas pÃºblicas estratÃ©gicamente falando para permitir previa visualizaÃ§Ã£o das funcionalidades da api e possibilitar integraÃ§Ã£o com o streamlit de monitoramento.
Para isso foi preciso criar uma aplicaÃ§Ã£o OAuth App no GitHub, onde obtemos o Client ID e o Client Secret e indicamos a url da home e a url de callback (o arquivo `app/.env` contÃªm as credenciais usadas na integraÃ§Ã£o da nossa api com o GitHub e Ã© usada a partir da classe Settings de `api/settings.py`. SÃ£o elas: CLIENT_ID, CLIENT_SECRET, CallBack_URL e SECRET_KEY)

### AutenticaÃ§Ã£o produtiva
Ao acessar nosso [site](https://mle-tech-chalenge-1.onrender.com/), a autenticaÃ§Ã£o Ã© bastante intuitiva, vocÃª apenas precisa ter uma conta no github e o restante serÃ¡ como uma autenticaÃ§Ã£o normal.

### AutenticaÃ§Ã£o sistÃªmica - para acessar em um  jupyter notebook
Nesse caso, a autenticaÃ§Ã£o requer alguns passos:
- 1. instale:
       ```python
       !pip install requests_oauthlib --force-reinstall
       ```
- 2. FaÃ§a o passo de autenticaÃ§Ã£o:
       ```python
       import requests
       from requests_oauthlib import OAuth2Session

       # Dados da aplicaÃ§Ã£o registrada no GitHub
       client_id = "Ov23liTFpiWL4zMuc5Tx"
       client_secret = "e1494122a9f7dbf97e3659dd48f609ba961a56f1"
       redirect_uri = "https://mle-tech-chalenge-1.onrender.com/callback"


       # URLs do GitHub
       authorization_base_url = "https://github.com/login/oauth/authorize"
       token_url = "https://github.com/login/oauth/access_token"


       # Criar sessÃ£o OAuth2
       github = OAuth2Session(client_id, redirect_uri=redirect_uri)

       # Passo 1: Obter URL de autorizaÃ§Ã£o
       authorization_url, state = github.authorization_url(authorization_base_url)
       print("Acesse este link para autorizar:", authorization_url)
       ## RefaÃ§a esse passo na mesma aba da primeira vez para que o callback esteja unitilizado e funcione corretamente jÃ¡ que a sessÃ£o no github ainda estarÃ¡ ativa.
       ```
- 3. Depois da segunda execuÃ§Ã£o, acesse a ferramenta DevTools do navegador para copiar o URL de redirecionamento completo que Ã© a callback:
       ```Python
       # Cole o URL de redirecionamento completo em redirect_response
       redirect_response = "https://mle-tech-chalenge-1.onrender.com/callback/?code=88a0f15c4c658edb5a29&state=L3QXDVNaZNpXEndsbMNGr9eQXW3Lmu"

       # Passo 2: Trocar o cÃ³digo pelo token de acesso
       token = github.fetch_token(
       token_url,
       client_secret=client_secret,
       authorization_response=redirect_response
       )

       print("Token de acesso:", token)
       ```
- 4. Pronto! Basta consumir a api
       ```python
       response = github.get("https://mle-tech-chalenge-1.onrender.com/api/v1/stats/overview", )
       print(response.json())
       ```

## Monitoring & Logs
Para enriquecer os logs da nossa API fizemos uso da biblioteca `logging` em cada funÃ§Ã£o e tambÃ©m no middleware `catch_exceptions_middleware` para centralizar a captura de exceptions.

Para monitorar a api, nÃ³s temos a captura de logs de cada rota tambÃ©m em `catch_exceptions_middleware`, usando a biblioteca `starlette`. A integraÃ§Ã£o com o banco de dados Ã© feita em `app/services/log.py`.

O dashboard de monitoramento estÃ¡ em https://mle-tech-chalenge-1-streamlit-qoud.onrender.com/

Abaixo, dois diagramas referentes aos logs.
- [`sequence_get_api_logs.md`](docs/uml/sequence_get_api_logs.md) â€” GET /api_logs (consulta de logs)
- [`class_api_log.md`](docs/uml/class_api_log.md) â€” Diagrama de classes do modelo `ApiLog`


## ğŸŒ Deploy

INCLUIR EXPLICAÃ‡ÃƒO DO RENDER

A API estÃ¡ disponÃ­vel publicamente em: 

ğŸ‘‰ [https://mle-tech-chalenge-1.onrender.com/](https://mle-tech-chalenge-1.onrender.com/)

## ğŸ“‘ Plano de IntegraÃ§Ã£o com Modelos de Machine Learning
### Objetivo
Este plano descreve como a API pÃºblica de livros serÃ¡ integrada com modelos de Machine Learning (ML), garantindo que os dados coletados via web scraping sejam disponibilizados de forma escalÃ¡vel, reutilizÃ¡vel e prontos para consumo em sistemas de recomendaÃ§Ã£o, anÃ¡lise estatÃ­stica e prediÃ§Ã£o.

### Fluxo de IntegraÃ§Ã£o com ML

#### IngestÃ£o de Dados

Cientistas de dados acessam /api/v1/ml/training-data para obter as bases de dados em formato JSON para treinamento.

#### AnÃ¡lise dos dados

Cientista de dados usam /api/v1/stats/overview e /api/v1/stats/categories para analisar a distribuiÃ§Ã£o dos dados por rating ou por categoria.
 
#### PreparaÃ§Ã£o de Features

Endpoint /api/v1/ml/features fornece dados jÃ¡ normalizados, facilitando integraÃ§Ã£o direta com frameworks como Scikit-learn, TensorFlow ou PyTorch.

#### Treinamento de Modelos

Modelos de recomendaÃ§Ã£o sÃ£o treinados usando os dados obtidos por requisiÃ§Ãµes e armazenados em catalogos de modelos para versionamento dos modelos.

#### Deploy de Modelos

Modelos sÃ£o expostos como serviÃ§os via FastAPI atravÃ©s do endpoint /api/v1/ml/predictions.

#### Consumo de PrediÃ§Ãµes

AplicaÃ§Ãµes externas chamam /api/v1/ml/predictions enviando dados de entrada. API retorna recomendaÃ§Ãµes personalizadas ou insights.

### CenÃ¡rios de Uso
- RecomendaÃ§Ã£o de Livros  
UsuÃ¡rio consulta /api/v1/ml/predictions e recebe sugestÃµes baseadas em categoria e rating.

- Treinamento de Modelos de ClassificaÃ§Ã£o  
Cientistas de dados usam /api/v1/ml/training-data para treinar modelos que classificam livros por popularidade ou faixa de preÃ§o.

- Dashboards AnalÃ­ticos  
Dados de /api/v1/stats/* podem ser integrados em ferramentas como Streamlit para visualizaÃ§Ã£o.

## âš ï¸ LimitaÃ§Ãµes Atuais e PrÃ³ximos Passos

Embora a soluÃ§Ã£o atenda plenamente aos objetivos propostos para esta fase do Tech Challenge, algumas limitaÃ§Ãµes tÃ©cnicas e funcionais foram identificadas e jÃ¡ estÃ£o mapeadas como prÃ³ximos passos de evoluÃ§Ã£o do projeto.

### LimitaÃ§Ãµes Atuais

- DependÃªncia da estrutura do site fonte

O processo de web scraping depende diretamente da estrutura HTML do site Books to Scrape. AlteraÃ§Ãµes no layout ou nos seletores podem exigir ajustes no script de extraÃ§Ã£o.

- Banco de dados SQLite
A aplicaÃ§Ã£o utiliza SQLite por simplicidade e facilidade de setup local. Essa soluÃ§Ã£o nÃ£o Ã© ideal para cenÃ¡rios de alta concorrÃªncia ou grandes volumes de dados.

- Scraping sÃ­ncrono
O scraping Ã© executado de forma sÃ­ncrona, podendo impactar o tempo de resposta da API quando acionado em produÃ§Ã£o.

- Endpoints de Machine Learning nÃ£o implementados
Os endpoints ML-ready (/ml/features, /ml/training-data, /ml/predictions) estÃ£o documentados e planejados, mas ainda nÃ£o fazem parte da versÃ£o atual da API.

- AusÃªncia de cache
NÃ£o hÃ¡ mecanismo de cache para respostas frequentes, o que pode gerar leituras repetidas do banco de dados.

### PrÃ³ximos Passos (EvoluÃ§Ã£o do Projeto)

- MigraÃ§Ã£o do banco de dados
  - Substituir o SQLite por um banco relacional mais robusto, como PostgreSQL, com uso de Redis para cache de consultas frequentes.

- Scraping assÃ­ncrono e agendado
  - Implementar scraping assÃ­ncrono e/ou agendado utilizando filas (ex.: Celery, RQ ou SQS) ou orquestradores como Airflow.

- ImplementaÃ§Ã£o completa do pipeline ML

  - Disponibilizar datasets prontos para treino
  - Criar um modelo inicial de recomendaÃ§Ã£o de livros
  - Versionar modelos e features

- Melhorias de seguranÃ§a

  - Rate limiting
  - Controle de permissÃµes por perfil
  - Tokens com expiraÃ§Ã£o e refresh automatizado

- Observabilidade avanÃ§ada

  - MÃ©tricas de performance (latÃªncia, throughput)
  - Alertas automatizados
  - Dashboards mais completos de monitoramento

- Escalabilidade e Cloud-Native

  - ContainerizaÃ§Ã£o com Docker
  - Deploy com CI/CD
  - Suporte a mÃºltiplas versÃµes da API

## Diagrama Visual
```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Web Scrapingâ”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚ Processing  â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚  Database   â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚     API REST         â”‚
   â”‚  /books /categories  â”‚
   â”‚  /ml/features        â”‚
   â”‚  /ml/training-data   â”‚
   â”‚  /ml/predictions     â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚   ML Model  â”‚
   â”‚ (Recommenderâ”‚
   â”‚   System)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Consumers/Apps   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---
## ğŸ—ï¸ Arquitetura
Pipeline de dados:
1. **IngestÃ£o** â†’ Web Scraping dos livros.  
2. **Processamento** â†’ TransformaÃ§Ã£o e armazenamento em CSV.  
3. **API** â†’ DisponibilizaÃ§Ã£o dos dados via endpoints RESTful.  
4. **Consumo** â†’ Cientistas de dados e serviÃ§os de recomendaÃ§Ã£o.  

ğŸ‘‰ [Diagrama Arquitetural link](https://drive.google.com/file/d/1AE_LhUABf7asm-2K3pkIXUFuG20Aajez/view?usp=sharing) <!-- substitua pelo seu diagrama -->

---

### ğŸ“‚ Estrutura do RepositÃ³rio

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ app
|   â”œâ”€â”€ db
â”‚   |   â””â”€â”€ books.db
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ book.py
â”‚   â”‚   â”œâ”€â”€ category.py
â”‚   â”‚   â”œâ”€â”€ stats.py
â”‚   â”‚   â””â”€â”€ logs.py
â”‚   â”œâ”€â”€ routers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ book.py
â”‚   â”‚   â”œâ”€â”€ category.py
â”‚   â”‚   â”œâ”€â”€ health.py
â”‚   â”‚   â”œâ”€â”€ scraping.py
â”‚   â”‚   â”œâ”€â”€ stats.py
|   |   â”œâ”€â”€ callback.py
â”‚   â”‚   â”œâ”€â”€ home.py
â”‚   â”‚   â”œâ”€â”€ login.py
â”‚   â”‚   â”œâ”€â”€ logout.py
â”‚   â”‚   â”œâ”€â”€ log.py
â”‚   â”‚   â””â”€â”€ nolog.py
â”‚   â”œâ”€â”€ services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ book.py
â”‚   â”‚   â”œâ”€â”€ category.py
â”‚   â”‚   â”œâ”€â”€ scraping.py
â”‚   â”‚   â”œâ”€â”€ stats.py
â”‚   â”‚   â”œâ”€â”€ auth_middleware.py
â”‚   â”‚   â””â”€â”€ log.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ constants.py
â”œâ”€â”€ create_db.py
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ db_models.md
â”‚   â”œâ”€â”€ scraping_architecture.drawio
â”‚   â””â”€â”€ uml/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ class_api_log.md
â”‚       â”œâ”€â”€ class_api_log.svg
â”‚       â”œâ”€â”€ class_diagram.md
â”‚       â”œâ”€â”€ class_diagram-1.png
â”‚       â”œâ”€â”€ class_diagram-1.svg
â”‚       â”œâ”€â”€ sequence_get_api_logs.md
â”‚       â”œâ”€â”€ sequence_get_api_logs.svg
â”‚       â”œâ”€â”€ sequence_get_book.md
â”‚       â”œâ”€â”€ sequence_get_book-1.png
â”‚       â”œâ”€â”€ sequence_get_book-1.svg
â”‚       â”œâ”€â”€ sequence_health.md
â”‚       â”œâ”€â”€ sequence_health-1.svg
â”‚       â”œâ”€â”€ sequence_list_books.md
â”‚       â”œâ”€â”€ sequence_list_books-1.svg
â”‚       â”œâ”€â”€ sequence_list_categories.md
â”‚       â”œâ”€â”€ sequence_list_categories-1.svg
â”‚       â”œâ”€â”€ sequence_price_range.md
â”‚       â”œâ”€â”€ sequence_price_range-1.svg
â”‚       â”œâ”€â”€ sequence_scrape_populate.md
â”‚       â”œâ”€â”€ sequence_scrape_populate-1.png
â”‚       â”œâ”€â”€ sequence_scrape_populate-1.svg
â”‚       â”œâ”€â”€ sequence_search_books.md
â”‚       â”œâ”€â”€ sequence_search_books-1.svg
â”‚       â”œâ”€â”€ sequence_stats_categories.md
â”‚       â”œâ”€â”€ sequence_stats_categories-1.svg
â”‚       â”œâ”€â”€ sequence_stats_overview.md
â”‚       â”œâ”€â”€ sequence_stats_overview-1.svg
â”‚       â”œâ”€â”€ sequence_top_rated.md
â”‚       â””â”€â”€ sequence_top_rated-1.svg
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-dev.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ tests
    â”œâ”€â”€ readme.md
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ test_auth_middleware.py
    â”œâ”€â”€ test_logs.py
    â”œâ”€â”€ test_models.py
    â”œâ”€â”€ test_routers.py
    â”œâ”€â”€ test_services.py
    â””â”€â”€ __pycache__/
```

---

## ğŸ“Œ Roadmap da execuÃ§Ã¤o Projeto pelo time

Este documento apresenta o planejamento do projeto em formato **roadmap**, dividido em sprints de 3 semanas, com visÃ£o estilo **Gantt** e **heatmap visual** para destacar dependÃªncias entre tarefas. Bem tb como o Trello de acompanhamento da evolucao do projeto.

---


## ğŸ“Š Roadmap por Semana â€“ Projeto API PÃºblica para Consulta de Livros

| Tarefa                          | Semana 1 | Semana 2 | Semana 3 | Semana 4 | Semana 5 | Semana 6 |
|---------------------------------|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|
| Setup & Scraping                | ğŸŸ©ğŸŸ©ğŸŸ©     |          |          |          |          |          |
| API Core                        |          | â†’ ğŸŸ¦ğŸŸ¦ğŸŸ¦   |          |          |          |          |
| Deploy & Arquitetura            |          |          | â†’ ğŸŸ¨ğŸŸ¨ğŸŸ¨   |          |          |          |
| Insights & EstatÃ­sticas         |          |          |          | â†’ ğŸŸªğŸŸªğŸŸª   |          |          |
| BÃ´nus & ML-ready                |          |          |          |          | â†’ ğŸŸ¥ğŸŸ¥ğŸŸ¥   |          |
| FinalizaÃ§Ã£o & ApresentaÃ§Ã£o      |          |          |          |          |          | â†’ ğŸŸ§ğŸŸ§ğŸŸ§   |

---

### ğŸ¨ Legenda de cores
- ğŸŸ© Setup & Scraping  
- ğŸŸ¦ API Core  
- ğŸŸ¨ Deploy & Arquitetura  
- ğŸŸª Insights & EstatÃ­sticas  
- ğŸŸ¥ BÃ´nus & ML-ready  
- ğŸŸ§ FinalizaÃ§Ã£o & ApresentaÃ§Ã£o  


- [Trello de evolucao do projeto](https://trello.com/b/7Lrv480a/tech-chalenge-i)
---

## ğŸ“Œ ObservaÃ§Ãµes

A aplicaÃ§Ã£o possui uma suÃ­te de testes. Execute `python -m pytest tests/ -v` localmente para ver o estado atual dos testes e consulte `tests/readme.md` para informaÃ§Ãµes sobre cobertura e relatÃ³rios (HTML).

**RelatÃ³rio HTML de cobertura:** [tests/htmlcov/index.html](tests/htmlcov/index.html)
    - Abra esse arquivo localmente no seu navegador para visualizaÃ§Ã£o interativa.

### PrÃ©-requisitos
- Python 3.9+
- Pip ou Poetry
- Conta em render.com

### Passos
bash
#### Clonar repositÃ³rio
```bash
git clone https://github.com/vagnerasilva/mle_tech_chalenge_1.git
cd seu-repo
```
#### Criar ambiente virtual
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

#### Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

#### Rodar API localmente
```bash
# Inicie o servidor de desenvolvimento
uvicorn app.app:app --reload
# Inicie o servidor de desenvolvimento em prod ( render)
uvicorn app.app:app --host 0.0.0.0 --port 10000 --reload
```

Â´Â´Â´

## Testes de response/requests 
Acesse [aqui](https://docs.google.com/document/d/1EdPdVxfSUCTN6JQGMQNRcEKVdiMOuGGmKpJxedEBpNM/edit?tab=t.0#heading=h.1b5y9g8r5jym)


## ğŸ† Boas PrÃ¡ticas

### ğŸ—ï¸ OrganizaÃ§Ã£o e Arquitetura

#### SeparaÃ§Ã£o de Responsabilidades por Camadas

- **Routers**: DefiniÃ§Ã£o dos endpoints e contratos da API
- **Services**: Regras de negÃ³cio e integraÃ§Ã£o com banco de dados
- **Models**: DefiniÃ§Ã£o das entidades e schemas
- **Utils**: Constantes e funÃ§Ãµes auxiliares

#### Estrutura de Projeto Modular

A modularizaÃ§Ã£o facilita:

- Testes automatizados
- ReutilizaÃ§Ã£o de cÃ³digo
- EvoluÃ§Ã£o incremental do sistema

---

### ğŸŒ Boas PrÃ¡ticas em APIs REST

- Uso consistente de verbos HTTP (GET, POST, etc.)
- Endpoints nomeados de forma semÃ¢ntica e previsÃ­vel
- Versionamento explÃ­cito via URL (`/api/v1`)
- Respostas padronizadas em formato JSON
- Uso adequado de cÃ³digos de status HTTP (200, 400, 401, 404, 500)

---

### ğŸ“ Qualidade de CÃ³digo

- CÃ³digo escrito seguindo padrÃµes da **PEP 8**
- FunÃ§Ãµes com responsabilidades bem definidas
- Evita duplicaÃ§Ã£o de lÃ³gica (**DRY** â€“ Don't Repeat Yourself)
- ComentÃ¡rios objetivos apenas quando necessÃ¡rio
- Tipagem explÃ­cita sempre que aplicÃ¡vel

---

### âš ï¸ Tratamento de Erros e Logs

#### CentralizaÃ§Ã£o de ExceÃ§Ãµes

- Tratamento centralizado via middleware (`catch_exceptions_middleware`)
- Mensagens de erro claras, sem expor informaÃ§Ãµes sensÃ­veis

#### Logs Estruturados

Utilizados para:
# Streamlit com statisticas do consumo da api 
ğŸ‘‰ Link Monitoramento: [Streamlit](https://mle-tech-chalenge-1-streamlit-qoud.onrender.com/)

![alt text](./docs/streamlit.png)

- Registro de erros e stack traces
- ExecuÃ§Ã£o de endpoints
- Monitoramento de performance
- Rastreamento de eventos importantes

ğŸ‘‰ repositorio do streamlit de monitoramento: [https://github.com/vagnerasilva/mle_tech_chalenge_1_streamlit/](https://github.com/vagnerasilva/mle_tech_chalenge_1_streamlit/)

# ğŸ“‘ Plano de IntegraÃ§Ã£o com Modelos de Machine Learning
## Objetivo
Este plano descreve como a API pÃºblica de livros serÃ¡ integrada com modelos de Machine Learning (ML), garantindo que os dados coletados via web scraping sejam disponibilizados de forma escalÃ¡vel, reutilizÃ¡vel e prontos para consumo em sistemas de recomendaÃ§Ã£o, anÃ¡lise estatÃ­stica e prediÃ§Ã£o.

### ğŸ” SeguranÃ§a

- Uso de autenticaÃ§Ã£o para proteger rotas sensÃ­veis
- SeparaÃ§Ã£o entre rotas pÃºblicas e rotas autenticadas
- VariÃ¡veis sensÃ­veis isoladas em arquivos de ambiente (`.env`)
- Evita hardcode de segredos no cÃ³digo-fonte
- IntegraÃ§Ã£o com OAuth2 via GitHub para autenticaÃ§Ã£o

---

### ğŸ§ª Testes Automatizados

#### Cobertura de Testes

A suÃ­te de testes abrange:

- Models
- Services
- Routers
- Middleware de autenticaÃ§Ã£o

#### Ferramentas e RelatÃ³rios

- Uso de **pytest** para execuÃ§Ã£o e organizaÃ§Ã£o dos testes
- RelatÃ³rio de cobertura para acompanhamento da qualidade
- Cobertura atual: **70%** (confira [tests/htmlcov/index.html](tests/htmlcov/index.html))

---

### ğŸ¤– PreparaÃ§Ã£o para Machine Learning (ML-Ready)

- Dados estruturados e normalizados no banco
- Endpoints planejados para:
  - ExtraÃ§Ã£o de datasets
  - GeraÃ§Ã£o de features
  - Consumo por pipelines de ML
- Foco em reprodutibilidade e versionamento dos dados

---

### ğŸ“Š Observabilidade e Monitoramento

- Registro de logs de todas as requisiÃ§Ãµes
- PersistÃªncia de mÃ©tricas bÃ¡sicas no banco de dados
- Dashboard externo para visualizaÃ§Ã£o de uso e performance
- Endpoint dedicado `/api_logs` para consulta de logs

# ğŸ¥ VÃ­deo de ApresentaÃ§Ã£o
ğŸ‘‰ Link do VÃ­deo


